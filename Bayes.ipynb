{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d359d365-d9bb-41ae-b05b-e97483a1a62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from scipy.stats import norm\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import matplotlib.pylab as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f6ae0-1f3e-4237-ace1-d166fec27909",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate a 2D gaussian with density \n",
    "def gauss_pdf(mean, cov, x):\n",
    "    return (1./(((2*np.pi)**(1.*len(mean)/2))*np.linalg.det(cov)**.5))*np.exp(-np.matrix(x-mean)*np.matrix(np.linalg.inv(cov))*np.matrix(x-mean).T/2 ).tolist()[0][0]\n",
    "\n",
    "N = 1000\n",
    "p = []\n",
    "mean = [1, 1]\n",
    "cov = [[1, -.25], [-.25, 1]]\n",
    "x = np.random.multivariate_normal(mean, cov, N)\n",
    "\n",
    "for n in range(N):\n",
    "    p.append( gauss_pdf(mean, cov, x[n]) )\n",
    "\n",
    "p = np.array(p)\n",
    "\n",
    "# plot the 2D RVs with the 3rd dim being the pdf value \n",
    "fig = plt.figure(dpi=500)\n",
    "ax = fig.gca(projection='3d')\n",
    "ax.scatter(x[:,0], x[:,1], p)\n",
    "ax.legend()\n",
    "plt.savefig('pdf/bayes-2d-norm-pdf.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9fbdc9-6bb4-4d4c-aa17-0aea9e8e4ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mahal(mean, cov, x):\n",
    "    return (-np.matrix(x-mean)*np.matrix(np.linalg.inv(cov))*np.matrix(x-mean).T/2 ).tolist()[0][0]\n",
    "\n",
    "\n",
    "x = np.random.multivariate_normal([-1, -1], [[1, -.5], [-.5, 1]], 50000)\n",
    "m = []\n",
    "for n in range(N):\n",
    "   m.append( gauss_pdf(mean, cov, x[n]) )\n",
    "\n",
    "x = x.T\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "d = plt.hist2d(x[0], x[1], bins = 75)\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.savefig('pdf/bayes-2d-norm-heatmap.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af9467de-0e38-4385-b8cf-da27e44273a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-3, 5, 500)\n",
    "\n",
    "pw1 = .6\n",
    "pw2 = .4\n",
    "pxw1 = norm.pdf(x, 3, .8)\n",
    "pxw2 = norm.pdf(x, 1, .6)\n",
    "px = pxw1*pw1+pxw2*pw2\n",
    "pwx1 = pxw1*pw1/px\n",
    "pwx2 = pxw2*pw2/px\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "plt.plot(x, pxw1, 'b-', lw=5, alpha=0.6, label='$p(x|\\omega_1)$')\n",
    "plt.plot(x, pxw2, 'r-', lw=5, alpha=0.6, label='$p(x|\\omega_2)$')\n",
    "plt.plot(x, pwx1, 'b--', lw=5, alpha=0.6, label='$p(\\omega_1|x)$')\n",
    "plt.plot(x, pwx2, 'r--', lw=5, alpha=0.6, label='$p(\\omega_2|x)$')\n",
    "plt.legend()\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('conditional probability')\n",
    "plt.savefig('pdf/bayes-post-likeli.pdf')\n",
    "\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "plt.plot(x, pxw1, 'b-', lw=5, alpha=0.6, label='$p(x|\\omega_1)$')\n",
    "plt.plot(x, pxw2, 'r-', lw=5, alpha=0.6, label='$p(x|\\omega_2)$')\n",
    "plt.legend()\n",
    "plt.fill_between(x, 0, pxw2, where=pxw1 > pxw2, facecolor='red', alpha=0.5)\n",
    "plt.fill_between(x, 0, pxw1, where=pxw2 > pxw1, facecolor='blue', alpha=0.5)\n",
    "plt.text(-2.9, .4, '$p_2 = \\int_{\\mathcal{R}_2}p(x|\\omega_1)p(\\omega_1)dx$', fontsize=15, color='b')\n",
    "plt.text(-2.9, .55, '$p_1 = \\int_{\\mathcal{R}_1}p(x|\\omega_2)p(\\omega_2)dx$', fontsize=15, color='r')\n",
    "plt.text(-2.9, .2, '$p_{err} = p_1+p_2$', fontsize=15)\n",
    "\n",
    "ax.arrow(1.9, 0.5, 2.1, 0.05, head_width=0.05, head_length=0.05, fc='k', ec='k')\n",
    "\n",
    "plt.xlabel('$x$')\n",
    "plt.ylabel('conditional probability')\n",
    "plt.savefig('pdf/bayes-likeli.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9554923d-3f40-4639-9f40-e252f4af949a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 300\n",
    "x1 = np.random.rand(n)\n",
    "x2 = np.random.exponential(1.0/.3, n)\n",
    "x3 = np.random.randn(n)\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "plt.hist(x1)\n",
    "plt.savefig('pdf/bayes-dist-uniform.pdf')\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "plt.hist(x2)\n",
    "plt.savefig('pdf/bayes-dist-exp.pdf')\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "plt.hist(x3)\n",
    "plt.savefig('pdf/bayes-dist-gaussian.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f43b565-2200-4de2-9f8c-0b879f402447",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_cb(N, a, alpha): \n",
    "    \"\"\"\n",
    "    N: number of points on the checkerboard\n",
    "    a: width of the checker board (0<a<1)\n",
    "    alpha: rotation of the checkerboard in radians \n",
    "    \"\"\"\n",
    "    d = np.random.rand(N, 2).T\n",
    "    d_transformed = np.array([d[0]*np.cos(alpha)-d[1]*np.sin(alpha), \n",
    "                              d[0]*np.sin(alpha)+d[1]*np.cos(alpha)]).T\n",
    "    s = np.ceil(d_transformed[:,0]/a)+np.floor(d_transformed[:,1]/a)\n",
    "    lab = 2 - (s%2)\n",
    "    data = d.T\n",
    "    return data, lab \n",
    "\n",
    "X, y = gen_cb(250, .5, 0)\n",
    "plt.figure(dpi=500)\n",
    "plt.plot(X[np.where(y==1)[0], 0], X[np.where(y==1)[0], 1], 'o')\n",
    "plt.plot(X[np.where(y==2)[0], 0], X[np.where(y==2)[0], 1], 's', c = 'r')\n",
    "plt.savefig('pdf/bayes-cb1.pdf')\n",
    "X, y = gen_cb(1000, .25, 3.14159/4)\n",
    "plt.figure(dpi=500)\n",
    "plt.plot(X[np.where(y==1)[0], 0], X[np.where(y==1)[0], 1], 'o')\n",
    "plt.plot(X[np.where(y==2)[0], 0], X[np.where(y==2)[0], 1], 's', c = 'r')\n",
    "plt.savefig('pdf/bayes-cb2.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff5604af-cd40-4457-9eec-a35fe4f077ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.multivariate_normal([-1, -1], [[1, -.5], [-.5, 1]], 50000)\n",
    "m = []\n",
    "for n in range(N):\n",
    "   m.append( gauss_pdf(mean, cov, x[n]) )\n",
    "\n",
    "x = x.T\n",
    "\n",
    "plt.figure(dpi=500)\n",
    "d = plt.hist2d(x[0], x[1], bins = 75)\n",
    "plt.plot(-2, -2, 'wo')\n",
    "plt.text(-2,-2.5, 'This point and the distribution', c='w')\n",
    "plt.xlabel('$x_1$')\n",
    "plt.ylabel('$x_2$')\n",
    "plt.savefig('pdf/bayes-mahal-pdf.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "541b305b-3562-440e-9c21-ecd5839d95a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, :2]  # we only take the first two features.\n",
    "y = iris.target\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 0.5, X[:, 0].max() + 0.5\n",
    "y_min, y_max = X[:, 1].min() - 0.5, X[:, 1].max() + 0.5\n",
    "\n",
    "plt.figure(2, figsize=(8, 6), dpi=500)\n",
    "plt.clf()\n",
    "\n",
    "# Plot the training points\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor=\"k\")\n",
    "plt.xlabel(\"Sepal length\")\n",
    "plt.ylabel(\"Sepal width\")\n",
    "\n",
    "plt.xlim(x_min, x_max)\n",
    "plt.ylim(y_min, y_max)\n",
    "#plt.xticks(())\n",
    "#plt.yticks(())\n",
    "plt.savefig('pdf/bayes-iris.pdf')\n",
    "\n",
    "# To getter a better understanding of interaction of the dimensions\n",
    "# plot the first three PCA dimensions\n",
    "fig = plt.figure(1, figsize=(8, 6), dpi=500)\n",
    "ax = Axes3D(fig, elev=-150, azim=110)\n",
    "X_reduced = PCA(n_components=3).fit_transform(iris.data)\n",
    "ax.scatter(\n",
    "    X_reduced[:, 0],\n",
    "    X_reduced[:, 1],\n",
    "    X_reduced[:, 2],\n",
    "    c=y,\n",
    "    cmap=plt.cm.Set1,\n",
    "    edgecolor=\"k\",\n",
    "    s=40,\n",
    ")\n",
    "ax.set_title(\"First three PCA directions\")\n",
    "ax.set_xlabel(\"PC1\")\n",
    "ax.w_xaxis.set_ticklabels([])\n",
    "ax.set_ylabel(\"PC2\")\n",
    "ax.w_yaxis.set_ticklabels([])\n",
    "ax.set_zlabel(\"PC3\")\n",
    "ax.w_zaxis.set_ticklabels([])\n",
    "plt.savefig('pdf/bayes-iris-pca.pdf')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bcd6122-a5bd-40e6-9e9a-c7c9a0eb1655",
   "metadata": {},
   "outputs": [],
   "source": [
    "class bayes_disc: \n",
    "    def __init__(self): \n",
    "        self.covs = [] \n",
    "        self.means = []\n",
    "        self.priors = [] \n",
    "        self.classes = None \n",
    "        \n",
    "    def fit(self, X, y): \n",
    "        self.classes = np.unique(y)\n",
    "        n_classes = len(self.classes)\n",
    "        \n",
    "        for c in self.classes: \n",
    "            self.means.append(np.mean(X[y==c], axis=0))\n",
    "            self.covs.append(np.cov(X[y==c].T))\n",
    "            self.priors.append((y==c).sum()/len(y))\n",
    "    \n",
    "    def predict(self, X): \n",
    "        gc = []\n",
    "        \n",
    "        for x in X: \n",
    "            Wc = -0.5*np.linalg.inv(self.covs[i])\n",
    "            wc = np.linalg.dot(np.linalg.inv(self.covs[i]), self.means[i])\n",
    "            w0 = np.log(self.priors[i]) - np.log(np.linalg.det(self.covs[i])) - 0.5*np.linalg.dot(np.linalg.dot(self.means[i],np.linalg.inv(self.covs[i])), self.means[i])\n",
    "            \n",
    "            for i,c in enumerate(self.classes):\n",
    "                gc.append( np.dot(np.dot(x, Wc), x) + np.dot(wc, x) + w0)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03f468-a6ac-475b-b606-a3ed5776d16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import linalg\n",
    "from matplotlib import colors\n",
    "import matplotlib as mpl\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "\n",
    "cmap = colors.LinearSegmentedColormap(\n",
    "    \"red_blue_classes\",\n",
    "    {\n",
    "        \"red\": [(0, 1, 1), (1, 0.7, 0.7)],\n",
    "        \"green\": [(0, 0.7, 0.7), (1, 0.7, 0.7)],\n",
    "        \"blue\": [(0, 0.7, 0.7), (1, 1, 1)],\n",
    "    },\n",
    ")\n",
    "plt.cm.register_cmap(cmap=cmap)\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Generate datasets\n",
    "def dataset_fixed_cov():\n",
    "    \"\"\"Generate 2 Gaussians samples with the same covariance matrix\"\"\"\n",
    "    n, dim = 300, 2\n",
    "    np.random.seed(0)\n",
    "    C = np.array([[0.0, -0.23], [0.83, 0.23]])\n",
    "    X = np.r_[\n",
    "        np.dot(np.random.randn(n, dim), C),\n",
    "        np.dot(np.random.randn(n, dim), C) + np.array([1, 1]),\n",
    "    ]\n",
    "    y = np.hstack((np.zeros(n), np.ones(n)))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def dataset_cov():\n",
    "    \"\"\"Generate 2 Gaussians samples with different covariance matrices\"\"\"\n",
    "    n, dim = 300, 2\n",
    "    np.random.seed(0)\n",
    "    C = np.array([[0.0, -1.0], [2.5, 0.7]]) * 2.0\n",
    "    X = np.r_[\n",
    "        np.dot(np.random.randn(n, dim), C),\n",
    "        np.dot(np.random.randn(n, dim), C.T) + np.array([1, 4]),\n",
    "    ]\n",
    "    y = np.hstack((np.zeros(n), np.ones(n)))\n",
    "    return X, y\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Plot functions\n",
    "def plot_data(lda, X, y, y_pred, fig_index):\n",
    "    splot = plt.subplot(2, 2, fig_index)\n",
    "    if fig_index == 1:\n",
    "        plt.title(\"Linear Discriminant Analysis\")\n",
    "        plt.ylabel(\"Data with\\n fixed covariance\")\n",
    "    elif fig_index == 2:\n",
    "        plt.title(\"Quadratic Discriminant Analysis\")\n",
    "    elif fig_index == 3:\n",
    "        plt.ylabel(\"Data with\\n varying covariances\")\n",
    "\n",
    "    tp = y == y_pred  # True Positive\n",
    "    tp0, tp1 = tp[y == 0], tp[y == 1]\n",
    "    X0, X1 = X[y == 0], X[y == 1]\n",
    "    X0_tp, X0_fp = X0[tp0], X0[~tp0]\n",
    "    X1_tp, X1_fp = X1[tp1], X1[~tp1]\n",
    "\n",
    "    # class 0: dots\n",
    "    plt.scatter(X0_tp[:, 0], X0_tp[:, 1], marker=\".\", color=\"red\")\n",
    "    plt.scatter(X0_fp[:, 0], X0_fp[:, 1], marker=\"x\", s=20, color=\"#990000\")  # dark red\n",
    "\n",
    "    # class 1: dots\n",
    "    plt.scatter(X1_tp[:, 0], X1_tp[:, 1], marker=\".\", color=\"blue\")\n",
    "    plt.scatter(\n",
    "        X1_fp[:, 0], X1_fp[:, 1], marker=\"x\", s=20, color=\"#000099\"\n",
    "    )  # dark blue\n",
    "\n",
    "    # class 0 and 1 : areas\n",
    "    nx, ny = 200, 100\n",
    "    x_min, x_max = plt.xlim()\n",
    "    y_min, y_max = plt.ylim()\n",
    "    xx, yy = np.meshgrid(np.linspace(x_min, x_max, nx), np.linspace(y_min, y_max, ny))\n",
    "    Z = lda.predict_proba(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z[:, 1].reshape(xx.shape)\n",
    "    plt.pcolormesh(\n",
    "        xx, yy, Z, cmap=\"red_blue_classes\", norm=colors.Normalize(0.0, 1.0), zorder=0\n",
    "    )\n",
    "    plt.contour(xx, yy, Z, [0.5], linewidths=2.0, colors=\"white\")\n",
    "\n",
    "    # means\n",
    "    plt.plot(\n",
    "        lda.means_[0][0],\n",
    "        lda.means_[0][1],\n",
    "        \"*\",\n",
    "        color=\"yellow\",\n",
    "        markersize=15,\n",
    "        markeredgecolor=\"grey\",\n",
    "    )\n",
    "    plt.plot(\n",
    "        lda.means_[1][0],\n",
    "        lda.means_[1][1],\n",
    "        \"*\",\n",
    "        color=\"yellow\",\n",
    "        markersize=15,\n",
    "        markeredgecolor=\"grey\",\n",
    "    )\n",
    "\n",
    "    return splot\n",
    "\n",
    "\n",
    "def plot_ellipse(splot, mean, cov, color):\n",
    "    v, w = linalg.eigh(cov)\n",
    "    u = w[0] / linalg.norm(w[0])\n",
    "    angle = np.arctan(u[1] / u[0])\n",
    "    angle = 180 * angle / np.pi  # convert to degrees\n",
    "    # filled Gaussian at 2 standard deviation\n",
    "    ell = mpl.patches.Ellipse(\n",
    "        mean,\n",
    "        2 * v[0] ** 0.5,\n",
    "        2 * v[1] ** 0.5,\n",
    "        180 + angle,\n",
    "        facecolor=color,\n",
    "        edgecolor=\"black\",\n",
    "        linewidth=2,\n",
    "    )\n",
    "    ell.set_clip_box(splot.bbox)\n",
    "    ell.set_alpha(0.2)\n",
    "    splot.add_artist(ell)\n",
    "    splot.set_xticks(())\n",
    "    splot.set_yticks(())\n",
    "\n",
    "\n",
    "def plot_lda_cov(lda, splot):\n",
    "    plot_ellipse(splot, lda.means_[0], lda.covariance_, \"red\")\n",
    "    plot_ellipse(splot, lda.means_[1], lda.covariance_, \"blue\")\n",
    "\n",
    "\n",
    "def plot_qda_cov(qda, splot):\n",
    "    plot_ellipse(splot, qda.means_[0], qda.covariance_[0], \"red\")\n",
    "    plot_ellipse(splot, qda.means_[1], qda.covariance_[1], \"blue\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 8), facecolor=\"white\", dpi=500)\n",
    "plt.suptitle(\n",
    "    \"Linear Discriminant Analysis vs Quadratic Discriminant Analysis\",\n",
    "    y=0.98,\n",
    "    fontsize=15,\n",
    ")\n",
    "for i, (X, y) in enumerate([dataset_fixed_cov(), dataset_cov()]):\n",
    "    # Linear Discriminant Analysis\n",
    "    lda = LinearDiscriminantAnalysis(solver=\"svd\", store_covariance=True)\n",
    "    y_pred = lda.fit(X, y).predict(X)\n",
    "    splot = plot_data(lda, X, y, y_pred, fig_index=2 * i + 1)\n",
    "    plot_lda_cov(lda, splot)\n",
    "    plt.axis(\"tight\")\n",
    "\n",
    "    # Quadratic Discriminant Analysis\n",
    "    qda = QuadraticDiscriminantAnalysis(store_covariance=True)\n",
    "    y_pred = qda.fit(X, y).predict(X)\n",
    "    splot = plot_data(qda, X, y, y_pred, fig_index=2 * i + 2)\n",
    "    plot_qda_cov(qda, splot)\n",
    "    plt.axis(\"tight\")\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.92)\n",
    "plt.savefig('pdf/bayes-lda-qda.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572c9dfe-3f56-435f-b362-49ad608d9e34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de1eb5-b90b-4278-96d9-a6e2c8091d5d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
